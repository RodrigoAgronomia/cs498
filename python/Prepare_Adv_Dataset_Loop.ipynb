{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import seaborn as sbn\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import  tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "\n",
    "    def __init__(self, w_layers, pred_layers):\n",
    "\n",
    "        super().__init__()\n",
    "              \n",
    "        # Weaher variables\n",
    "        w_layers_list = nn.ModuleList()\n",
    "        for i, o, k, d in w_layers:\n",
    "            w_layer = nn.Sequential(\n",
    "                nn.Conv1d(i, o, k),\n",
    "                nn.AvgPool1d(2),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.BatchNorm1d(o),\n",
    "                nn.Dropout(d)\n",
    "            )\n",
    "            w_layers_list.append(w_layer)\n",
    "        w_layers_list.append(nn.AdaptiveAvgPool1d(1))\n",
    "        self.w_layers = nn.Sequential(*w_layers_list)\n",
    "\n",
    "        \n",
    "        # Management variables\n",
    "        pred_layers_list = nn.ModuleList()\n",
    "        for i, o, d in pred_layers:\n",
    "            pred_layer = nn.Sequential(\n",
    "                nn.Linear(i, o),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.BatchNorm1d(o),\n",
    "                nn.Dropout(d)\n",
    "            )\n",
    "            pred_layers_list.append(pred_layer)\n",
    "        pred_layers_list.append(nn.Linear(o, 1))\n",
    "        self.pred_layers = nn.Sequential(*pred_layers_list)\n",
    "        \n",
    "   \n",
    "    def forward(self, Ws):\n",
    "        \n",
    "        feat = self.w_layers(Ws).view(Ws.shape[0], -1)\n",
    "        pred = self.pred_layers(feat)\n",
    "        return (torch.tanh(pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(w):\n",
    "    ws = np.array([[[5e4,50,50,5,100.0]]])\n",
    "    w = w / ws\n",
    "    w = np.moveaxis(w, 1, 2)\n",
    "    wd = np.linspace(-0.9,2.1,300)[None,None]\n",
    "    wd = wd.repeat(len(w), 0)\n",
    "    w = np.concatenate([w, wd], 1)\n",
    "    w = torch.tensor(w, dtype=torch.float, device = device)\n",
    "    return(w)\n",
    "\n",
    "def back_transform(w):\n",
    "    w = w[:,:-1].cpu().data.numpy()\n",
    "    w = np.moveaxis(w, 2, 1)\n",
    "    ws = np.array([[[5e4,50,50,5,100.0]]])\n",
    "    w = w * ws\n",
    "    return(w[0])\n",
    "\n",
    "\n",
    "def get_adv(x, eps = 1):\n",
    "    xo = x.clone()\n",
    "    x.requires_grad = True\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam([x], lr=0.01)\n",
    "\n",
    "    for i in range(10):\n",
    "\n",
    "        # Limpa os gradientes\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Obtem o output\n",
    "        outputs = model(x)\n",
    "\n",
    "        # Calcula a perda pela loss function\n",
    "        loss = -outputs.mean()\n",
    "\n",
    "        # Use an l2 penalty:\n",
    "        loss += criterion(w_std * xo, w_std * x)/eps\n",
    "\n",
    "        # Obtem os gradientes\n",
    "        loss.backward()\n",
    "\n",
    "        # Atualiza os par√¢metros\n",
    "        optimizer.step()\n",
    "\n",
    "        # Clip to the valid range of values:\n",
    "        x.data = torch.clamp(x.data, 0, 1)\n",
    "        x.data[:,-1] = xo[:,-1]\n",
    "\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 0.0\n",
    "w_layers =  [[6,12,3,d],[12,15,5,d],[15,20,7,d],[20,25,5,d],[25,100,3,d]]\n",
    "pred_layers = [[100,50,d],[50,50,d], [50,25,d]]\n",
    "\n",
    "\n",
    "# model = MyNet(w_layers, pred_layers)\n",
    "# model = model.to(device)\n",
    "    \n",
    "# model_file_name = '../data/model_cnn_rnd_0.1.pth'\n",
    "# model.load_state_dict(torch.load(model_file_name, map_location=device))\n",
    "# model.eval()\n",
    "# print('Model OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values used to scale the weather data:\n",
    "ws = np.array([[[5e4,50,50,5,100.0]]])\n",
    "w_std = np.array([0.08034062, 0.08567557, 0.08080445, 0.14946058, 0.10540102,0.0])\n",
    "w_std = torch.tensor(w_std, device = device, dtype = torch.float)[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ydf = pd.read_hdf('../data/PSCE_TILE.h5', key = 'SIM').set_index('SIM')\n",
    "ydf['Yield'] = (ydf.TWSO/2e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdir = '/home/rodrigo7/Apsim_test/MASAGRO/DAYMET_TILE'\n",
    "pxy = np.stack(np.meshgrid(np.arange(40), np.arange(40)), -1).reshape(-1, 2)\n",
    "wfiles = [f'{wdir}/DAYMET_9584_{px:02d}_{py:02d}.csv' for px, py in pxy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wridx = []\n",
    "# for wfile in wfiles:   \n",
    "#     ridx = 10 * np.arange(8,10) + np.random.randint(0, 10, 2)\n",
    "#     wridx.append(ridx)\n",
    "# wridx = np.array(wridx)\n",
    "# np.save('../data/adv_idx.npy', wridx)\n",
    "wridx = np.load('../data/adv_idx.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b75802723a504db9b252e615672b5769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1600.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "052acb401a964b60abf41d94c3458b4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1600.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f16dde8db414c2c8c1ac1f84882223c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1600.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33aca31744bc4d53ad69bce20bce65d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1600.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_methods = ['none', 'rnd', 'adv']\n",
    "\n",
    "for REP in range(1, 6):\n",
    "    for train_method in train_methods:\n",
    "        for PCT in [1,5]:\n",
    "            model = MyNet(w_layers, pred_layers)\n",
    "            model = model.to(device)\n",
    "            model_file_name = f'../data/model_cnn_{train_method}_{PCT}_{REP}.pth'\n",
    "    \n",
    "            model.load_state_dict(torch.load(model_file_name, map_location=device))\n",
    "            model.eval()\n",
    "\n",
    "            yl = []\n",
    "            wfile = wfiles[10]\n",
    "            for wfile, ridx in zip(tqdm(wfiles), wridx):   \n",
    "                site = os.path.basename(wfile).replace('.csv', '')\n",
    "\n",
    "                w = pd.read_csv(wfile, skiprows = 13)\n",
    "                w.DAY = pd.to_datetime(w.DAY, format = '%Y%m%d').dt.date\n",
    "                sydf = ydf.loc[site]\n",
    "\n",
    "                wwf = []\n",
    "                for crop_start_date in sydf.SIM_DATE.values[ridx]:\n",
    "                    cs_date = np.where(w.DAY == crop_start_date)[0][0]\n",
    "                    wrng = slice(cs_date-90, cs_date+210)\n",
    "                    w_SIM = w.iloc[wrng].copy()\n",
    "                    w_seed = transform(w_SIM.iloc[:,[1,2,3,4,6]].values)\n",
    "                    y_pred = model(w_seed).data.cpu().numpy()\n",
    "                    w_adv = get_adv(w_seed, epsilon)\n",
    "                    y_adv = model(w_adv).data.cpu().numpy()\n",
    "                    w_adv = back_transform(w_adv)\n",
    "                    yl.append([y_pred, y_adv])\n",
    "\n",
    "\n",
    "                    w_SIM.iloc[:,[1,2,3,4,6]] = w_adv\n",
    "                    w_SIM.VAP = np.clip(w_SIM.VAP, 0.06, 199.3)\n",
    "\n",
    "                    plant_date = format(crop_start_date, '%Y%m%d')\n",
    "                    save_file = wfile.replace('.csv', f'_{plant_date}_opt_{train_method}_05.csv')\n",
    "                    with open(save_file, 'w') as sf:\n",
    "                        with open(wfile) as f:\n",
    "                            for r in range(14):\n",
    "                                sf.writelines(f.readline())\n",
    "\n",
    "                    w_SIM.DAY = pd.to_datetime(w_SIM.DAY).dt.strftime('%Y%m%d')\n",
    "                    w_SIM.to_csv(save_file, na_rep = 'NaN', mode = 'a', float_format = '%.3f', header = False, index = False)\n",
    "\n",
    "            ynp = 2e4 * np.array(yl)[:,:,0,0]\n",
    "            np.save(f'../data/y_pred_opt_{train_method}_05.npy', ynp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:GEOANN]",
   "language": "python",
   "name": "conda-env-GEOANN-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
